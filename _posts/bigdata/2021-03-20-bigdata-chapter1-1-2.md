---
layout: page
title: "빅데이터 분석 기사 1-1-2"
description: "학습"
headline: "빅데이터 분석 기사"
categories: bigdata_certificate
comments: true
published: true
---

# 빅데이터 분석 기획

### 1. 빅데이터  기술 및 제도

1. ##### 빅데이터 플랫폼

   - 빅데이터 플랫폼 : 빅데이터에서 가치를 추출하기 위해 일련의 과정(수집 - 저장 - 처리 - 분석 - 시각화)을 규격화한 기술

     

   - 빅데이터 플랫폼 구성요소
   
   - | 구성요소    | 주요 기능                                                    |
     | :---------- | :----------------------------------------------------------- |
     | 데이터 수집 | 원천 데이터의 정형 / 반정형 / 비정형 데이터 수집 <br /> ETL, 크롤러 EAI 등 |
     | 데이터 저장 | 정형 데이터, 반정형 데이터, 비정형 데이터 저장<br /> RDBMS, NoSQL 등 |
  | 데이터 분석 | 텍스트 분석, 머신러닝, 통계, 데이터 마이닝<br /> SNS 분석, 예측 분석 등 |
     | 데이터 활용 | 데이터 가시화 및 BI, Open API 연계<br /> 히스토그램, 인포그래픽 등 |

     

   - 빅데이터 플랫폼 데이터 형식

   - | 형식 | 특징                                                         |
   | :--- | :----------------------------------------------------------- |
      | HTML | 웹 페이지를 만들 때 사양되는 문서 형식<br /> 텍스트, 태그, 스크립트로 구성 |
      | XML  | SGML 문서 형식을 가진, 다른 특수한 목적을 갖는 마크업 언어를 만드는 데 사용하는 다목적 마크업 언어<br /> 데이터 표현을 위해 태그 사용<br /> 엘리먼트, 속성, 처리 명령, 엔티티, 주석, CDATE 섹션으로 구성 |
      | CSV  | 몇 가지 필드를 쉼표(,)로 구분한 텍스트 데이터 및 텍스트 파일 |
      | JSON | <키-값>으로 이루어진 데이터 오브젝트를 전달하기 위해 텍스트를 사용하는 개념형 표준 포맷 |
      
      
      
   - 빅데이터 플랫폼 구축 소프트웨어
   
- | 소프트웨어  |       핵심        |
     | :---------: | :---------------: |
  |      R      |   빅데이터 분석   |
     | 우지(Oozie) |  워크플로우 관리  |
  | 플럼(Flume) |    데이터 수집    |
     |    HBase    | 분산 데이터베이스 |
     | 스쿱(Sqoop) | 정형 데이터 수집  |
   
     
   
   - 분산 컴퓨팅 환경 소프트웨어 구성요소
   
   - | 구분                       | 주요 특징                                                    |
     | -------------------------- | ------------------------------------------------------------ |
     | 맵리듀스 Map Reduce        | key-value 형태의 데이터 처리<br /> 맵 - 셔플 - 리듀스 순서대로 처리<br /> - 맵 : key - value 형태로 데이터를 취합<br /> - 셔플 : 데이터를 통합하여 처리<br /> - 리듀스 : 맵 처리된 데이터를 정리 |
     | 얀 YARN                    | 하둡의 맵리듀스 처리 부분을 새롭게 만든 자원 관리 플랫폼 <br />리소스 매니저(Mater)와 노드 매니저(Slave)로 구성<br /> - 리소스 매니저 : 스케줄러 역할, 클러스터 이용률 최적화 수행<br /> - 노드 매니저 : 노드 내의 자원을 관리, 리소스 매니저에게 전달 수행 및 컨테이너 관리<br /> - 애플리케이션 마스터 : 리소스 매니저와 자원의 교섭을 책임지고, 컨테이너를 실행<br /> - 컨테이너 : 프로그램 구동을 위한 격리 환경을 지원하는 가상화 지원 |
     | 아파치 스파크 Apache Spark | 하둡 기반 대규모 데이터 분산처리시스팀<br /> 실시간 데이터 처리 |
     | 하둡 분산 파일 시스템 HDFS | 대용량 파일을 분산된 서버에 저장, 저장된 데이터를 빠르게 처리할 수 있게 하는 시스템<br /> 네임 노드와 데이터 노드로 구성<br /> 네임 노드 : 파일 이름, 권한 등의 속성 기록<br /> 데이터 노드 : 일정한 크기로 나눈 블록 형태로 저장 |
     | 아파치 하둡 Apache Hadoop  | 분산 파일 시스템과 맵리듀스를 중심으로 다양한 프로그램으로 구성된 하둡 에코시스템을 가짐<br />클라우드 플랫폼 위에서 클러스터를 구성해 데이터 분석 |
   
      
   
   - 하둡 에코시스템 : 하둡 프레임워크를 이루고 있는 다양한 서브 프로젝트들의 모임
   
   - | 구분               | 기술                | 설명                                                         |
     | ------------------ | ------------------- | ------------------------------------------------------------ |
     | 비정형 데이터 수집 | 척와 Chukwa         | 분산된 각 서버에서 에이전트를 실행하고, 컬렉터가 에이전트로부터 데이터를 받아 HDFS에 저장 |
     |                    | 플럼 Flume          | 많은 양의 로그 데이터를 효율적으로 수집, 집계, 이동하기 위해 이벤트와 에이전트를 활용하는 기술 |
     |                    | 스크라이브  Scribe  | 다수의 서버로부터 실시간으로 스트리밍되는 로그 데이터를 수집하여 분산 시스템에 데이터를 저장하는 대용량 실시간 로그 수집 기술 |
     | 정형 데이터 수집   | 스쿱 Sqoop          | 대용량 데이터 전송 솔루션<br /> 커넥터를 사용하여 RDBMS에서 HDFS로 데이터를 수집하거나 HDFS에서 RDBMS로 데이터를 보내는 기능 수행 |
     |                    | 히호 Hiho           | 스쿱과 같은 대용량 데이터 전송 솔루션                        |
     | 분산 데이터 저장   | HDFS                | 대용량 파일을 분산된 서버에 저장하고, 저장된 데이터를 빠르게 처리할 수 있게 하는 하둡 분산 파일 시스템<br /> 다중 복제, 대량 파일 저장, 온라인 변경, 범용서버 기반, 자동복구 특징이 있음 |
     | 분산 데이터 처리   | 맵리듀스 Map Reduce | 대용량 데이터 세트를 분산 병렬 컴퓨팅에서 처리하거나 생성하기 위한 목적으로 만들어진 소프트웨어 프레임 워크<br /> 모든 데이터는 키-값 쌍으로 구성, 데이터를 분류 |
     | 분산 데이터베이스  | HBase               | 컬림 기반 저장소로 HDFS와 인터페이스 제공<br /> 실시간 랜덤 조회 및 업데이트 가능, 각각의 프로세스는 개인의 데이터를 비동기적으로 업데이트 |
   
     
   
   - 하둡 에코 시스템의 데이터 가공 및 분석, 관리를 위한 주요 기술
   
   - | 구분            | 기술             | 설명                                                         |
     | --------------- | ---------------- | ------------------------------------------------------------ |
     | 데이터 가공     | 피그 Pig         | 대용량 데이터 집합을 분석하기 위한 플랫폼<br /> 맵리듀스 API를 매우 단순화시키고, SQL과 유사한 형태로 설계 |
     |                 | 하이브 Hive      | 하둡 기반의 DW 솔루션<br />SQL과 유사한 HiveQL라는 쿼리를 제공<br /> HiveQL은 내부적으로 맵리듀스로 변환되어 실행 |
     | 데이터 마이닝   | 머하웃 Mahout    | 하둡 기반으로 데이터 마이닝 알고리즘을 구현한 오픈 소스<br /> 분류, 클러스터링, 추천 및 협업 필터링, 패턴 마이닝, 회귀 분석, 진화 알고리즘 등 주요 알고리즘 지원 |
     | 실시간 SQL 질의 | 임팔라 Impala    | 하둡 기반의 실시간 SQL 질의 시스템                           |
     | 워크플로우 관리 | 우지 Oozie       | 하둡 작업을 관리하는 워크플로우 및 코디네이터 시스템         |
     | 분산 코디네이션 | 주키퍼 Zookeeper | 분산 환경에서 서버들 간에 상호 조정이 필요한 다양한 서비스를 제공<br /> 서비스를 알맞게 분산 처리, 동기화하여 데이터의 안정성을 보장 |
   
     
   
   

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

  

2. ##### 빅데이터와 인공지능 ★

   - 경제적 자산 : 새로운 기회 창출, 위험 해결, 경제 발전의 엔진 역할
   - 불확실성 제거 : 데이터를 기반으로 한 패턴 분석과 미래 전망, 여러 가능성에 대한 시나리오 시뮬레이션
   - 리스크 감소 : 패턴 분석을 통해 위험 징후 및 이상 신호 포착, 빠른 의사 결정과 실시간 대응
   - 스마트한 경쟁력 : 상황 인지,  인공지능 서비스 기능 
   - 타 분야 융합 : 융합을 통한 새로운 가치 창출

​	 데이터 활용 방식, 새로운 가치 창출, 분석기술 발전으로 인해 빅데이터의 가치를 정확하게 산정하기 어려움

> ###### 빅데이터 위기 요인
>
>    - 사생활 침해
>    - 책임 원칙 훼손 : 알고리즘의 희생양이 될 가능성
>    - 데이터 오용 : 데이터에 의존하기에 오류가 존재
>
> ###### 빅데이터 위기요인 통제 방안
>
>    - 알고리즘에 대한 접근 허용 : 예측 알고리즘의 부당함을 반증할 수 있는 알고리즘에 대한 접근권 제공
>    - 책임의 강조
>    - 결과 기반의 책임 적용



----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------



3. ##### 빅데이터 산업의 이해

   빅데이터 산업 개요

   - 클라우드 컴퓨팅 기술의 발전으로 데이터 처리 비용이 급격하게 감소, 빅데이터 발전
   - 데이터 생산량이 많은 산업이 발달해 잠재력이 크지만, 불확실성에 따른 투자 리스크 등으로 활용은 저조

   

4. ##### 빅데이터 조직 및 인력 ★★★

   1) 빅데이터 업무 프로세스 : 빅데이터 도입 - 빅데이터 구축 - 빅데이터 운영

   - 빅데이터 도입 : 빅데이터 도입 기획, 기술 검토, 도입 조직 구성, 예산 확보 등
   - 빅데이터 구축 : 요구사항 분석, 설계, 구현, 테스트 단계
   - 빅데이터 운영 : 빅데이트 플랫폼 및 분석 모델 운영

    

   2) 조직 설계 절차

   - 경영 전력 및 사업 전략 수립
   - 전체 조직 구조 설계
   - 핵심 업무 프로세스 검토
   - 팀 조직 구조 설계
   - 핵심 인력 선발
   - 역할과 책임 할당
   - 성과 측정 기준 수립
   - 역량 교육 및 훈련

   

   3) 조직 구조 설계 요소

    - 업무 활동 

      - 수직 업무 활동 : 경영 계획, 예산 할당 등 우선순위를 결정
      - 수평 업무 활동 : 업무 프로세스 절차별로 업무를 배분

   - 부서화 : 조직의 미션과 목적을 효율적으로 달성하기 위한 조직 구조 유형 설계

     - 집중 구조 : 전사 분석 업무를 별도의 분석 전담 조직에서 담당, 현업 업무부서의 분석 업무와 중복 및 이원화 가능성이 높음
     - 기능 구조 : 일반적인 형태로 별도 분석조직이 없고 해당 부서에서 분석 수행, 전사적 핵심 분석이 어려우며 과거에 국한된 분석 수행
     - 분산 구조 : 분석조직 인력들을 현업 부서로 직접 배치해 분석 업무를 수행, 분석 결과에 따른 신속한 피드백이 나오고 베스트 프랙티스 공유 가능
       <br />    업무과다와 이원화 가능성이 존재 할 수 있어 부서 분석 업무와 역할 분담이 명확해야 함   
       ![png](/assets/images/bigdata/bd_1.png) DSCoe - 데이터 사이언스 전문가 조직

     - 데이터 사이언티스트 요구역량 ★

       - 소프트 스킬 
         - 분석의 통찰력
         - 여러 분야의 협력 능력
         - 설득력 있는 전달력
       - 하드 스킬
         - 빅데이터 관련 이론적 지식
         - 분석기술의 숙련도

       

   4) 조직 구조의 설계 특성

   - 공식화
   - 분업화
   - 직무 전문화
   - 통제 범위
   - 의사소통 및 조정



  5) 역량 모델링 

> ① 역량 모델 : 우수 성과자의 행동하는 특성을 파악하여 업무 달성을 위한 지식, 스킬, 태도 등 직무 역량 요소들을 도출한 것
>
> ② 역량 모델 개발 절차 : 조직의 미션, 성과 목표, CSF검토 - 구성원의 행동 특성 도출 - 구성원의 역량 도출 - 조직 구성의 역량 모델 확정
>
> ③ 역량 교육 체계 설계 절차 : 요구사항 분석 - 직무별 역량 모델 검토 - 역량 차이 분석 - 직무 역량 매트릭스 작성 - 직무별 역량 교육 체계 설계

​	6) 조직성과 평가

> ① 조직성과 평가 절차 : 목표 설정 - 모니터링 - 목표 조정 - 평가 실시 - 결과의 피드백
>
> ② 균형성과표(BSC : Balanced Score Card) 4가지 관점 : 재무, 고객, 내부 프로세스, 학승과 성장

​					