---
layout: page
title: "빅데이터 분석 기사 1-1-2"
description: "학습"
headline: "빅데이터 분석 기사"
categories: bigdata_certificate
comments: true
published: true
---

# 빅데이터 분석 기획

### 1. 빅데이터  기술 및 제도

1. ##### 빅데이터 플랫폼

   - 빅데이터 플랫폼 : 빅데이터에서 가치를 추출하기 위해 일련의 과정(수집 - 저장 - 처리 - 분석 - 시각화)을 규격화한 기술

     

   - 빅데이터 플랫폼 구성요소
   
   - | 구성요소    | 주요 기능                                                    |
     | :---------- | :----------------------------------------------------------- |
     | 데이터 수집 | 원천 데이터의 정형 / 반정형 / 비정형 데이터 수집 <br /> ETL, 크롤러 EAI 등 |
     | 데이터 저장 | 정형 데이터, 반정형 데이터, 비정형 데이터 저장<br /> RDBMS, NoSQL 등 |
    | 데이터 분석 | 텍스트 분석, 머신러닝, 통계, 데이터 마이닝<br /> SNS 분석, 예측 분석 등 |
     | 데이터 활용 | 데이터 가시화 및 BI, Open API 연계<br /> 히스토그램, 인포그래픽 등 |

     

   - 빅데이터 플랫폼 데이터 형식

   - | 형식 | 특징                                                         |
   | :--- | :----------------------------------------------------------- |
     | HTML | 웹 페이지를 만들 때 사양되는 문서 형식<br /> 텍스트, 태그, 스크립트로 구성 |
     | XML  | SGML 문서 형식을 가진, 다른 특수한 목적을 갖는 마크업 언어를 만드는 데 사용하는 다목적 마크업 언어<br /> 데이터 표현을 위해 태그 사용<br /> 엘리먼트, 속성, 처리 명령, 엔티티, 주석, CDATE 섹션으로 구성 |
     | CSV  | 몇 가지 필드를 쉼표(,)로 구분한 텍스트 데이터 및 텍스트 파일 |
     | JSON | <키-값>으로 이루어진 데이터 오브젝트를 전달하기 위해 텍스트를 사용하는 개념형 표준 포맷 |
     
      
     
   - 빅데이터 플랫폼 구축 소프트웨어
   
- | 소프트웨어  |       핵심        |
     | :---------: | :---------------: |
  |      R      |   빅데이터 분석   |
  | 우지(Oozie) |  워크플로우 관리  |
  | 플럼(Flume) |    데이터 수집    |
  |    HBase    | 분산 데이터베이스 |
  | 스쿱(Sqoop) | 정형 데이터 수집  |
  
     
  
   - 분산 컴퓨팅 환경 소프트웨어 구성요소
  
   - | 구분                       | 주요 특징                                                    |
     | -------------------------- | ------------------------------------------------------------ |
     | 맵리듀스 Map Reduce        | key-value 형태의 데이터 처리<br /> 맵 - 셔플 - 리듀스 순서대로 처리<br /> - 맵 : key - value 형태로 데이터를 취합<br /> - 셔플 : 데이터를 통합하여 처리<br /> - 리듀스 : 맵 처리된 데이터를 정리 |
     | 얀 YARN                    | 하둡의 맵리듀스 처리 부분을 새롭게 만든 자원 관리 플랫폼 <br />리소스 매니저(Mater)와 노드 매니저(Slave)로 구성<br /> - 리소스 매니저 : 스케줄러 역할, 클러스터 이용률 최적화 수행<br /> - 노드 매니저 : 노드 내의 자원을 관리, 리소스 매니저에게 전달 수행 및 컨테이너 관리<br /> - 애플리케이션 마스터 : 리소스 매니저와 자원의 교섭을 책임지고, 컨테이너를 실행<br /> - 컨테이너 : 프로그램 구동을 위한 격리 환경을 지원하는 가상화 지원 |
     | 아파치 스파크 Apache Spark | 하둡 기반 대규모 데이터 분산처리시스팀<br /> 실시간 데이터 처리 |
     | 하둡 분산 파일 시스템 HDFS | 대용량 파일을 분산된 서버에 저장, 저장된 데이터를 빠르게 처리할 수 있게 하는 시스템<br /> 네임 노드와 데이터 노드로 구성<br /> 네임 노드 : 파일 이름, 권한 등의 속성 기록<br /> 데이터 노드 : 일정한 크기로 나눈 블록 형태로 저장 |
     | 아파치 하둡 Apache Hadoop  | 분산 파일 시스템과 맵리듀스를 중심으로 다양한 프로그램으로 구성된 하둡 에코시스템을 가짐<br />클라우드 플랫폼 위에서 클러스터를 구성해 데이터 분석 |
  
      
  
   - 하둡 에코시스템 : 하둡 프레임워크를 이루고 있는 다양한 서브 프로젝트들의 모임
  
   - | 구분               | 기술                | 설명                                                         |
     | ------------------ | ------------------- | ------------------------------------------------------------ |
     | 비정형 데이터 수집 | 척와 Chukwa         | 분산된 각 서버에서 에이전트를 실행하고, 컬렉터가 에이전트로부터 데이터를 받아 HDFS에 저장 |
     |                    | 플럼 Flume          | 많은 양의 로그 데이터를 효율적으로 수집, 집계, 이동하기 위해 이벤트와 에이전트를 활용하는 기술 |
     |                    | 스크라이브  Scribe  | 다수의 서버로부터 실시간으로 스트리밍되는 로그 데이터를 수집하여 분산 시스템에 데이터를 저장하는 대용량 실시간 로그 수집 기술 |
     | 정형 데이터 수집   | 스쿱 Sqoop          | 대용량 데이터 전송 솔루션<br /> 커넥터를 사용하여 RDBMS에서 HDFS로 데이터를 수집하거나 HDFS에서 RDBMS로 데이터를 보내는 기능 수행 |
     |                    | 히호 Hiho           | 스쿱과 같은 대용량 데이터 전송 솔루션                        |
     | 분산 데이터 저장   | HDFS                | 대용량 파일을 분산된 서버에 저장하고, 저장된 데이터를 빠르게 처리할 수 있게 하는 하둡 분산 파일 시스템<br /> 다중 복제, 대량 파일 저장, 온라인 변경, 범용서버 기반, 자동복구 특징이 있음 |
     | 분산 데이터 처리   | 맵리듀스 Map Reduce | 대용량 데이터 세트를 분산 병렬 컴퓨팅에서 처리하거나 생성하기 위한 목적으로 만들어진 소프트웨어 프레임 워크<br /> 모든 데이터는 키-값 쌍으로 구성, 데이터를 분류 |
     | 분산 데이터베이스  | HBase               | 컬림 기반 저장소로 HDFS와 인터페이스 제공<br /> 실시간 랜덤 조회 및 업데이트 가능, 각각의 프로세스는 개인의 데이터를 비동기적으로 업데이트 |
  
     
  
   - 하둡 에코 시스템의 데이터 가공 및 분석, 관리를 위한 주요 기술
  
   - | 구분            | 기술             | 설명                                                         |
     | --------------- | ---------------- | ------------------------------------------------------------ |
     | 데이터 가공     | 피그 Pig         | 대용량 데이터 집합을 분석하기 위한 플랫폼<br /> 맵리듀스 API를 매우 단순화시키고, SQL과 유사한 형태로 설계 |
     |                 | 하이브 Hive      | 하둡 기반의 DW 솔루션<br />SQL과 유사한 HiveQL라는 쿼리를 제공<br /> HiveQL은 내부적으로 맵리듀스로 변환되어 실행 |
     | 데이터 마이닝   | 머하웃 Mahout    | 하둡 기반으로 데이터 마이닝 알고리즘을 구현한 오픈 소스<br /> 분류, 클러스터링, 추천 및 협업 필터링, 패턴 마이닝, 회귀 분석, 진화 알고리즘 등 주요 알고리즘 지원 |
     | 실시간 SQL 질의 | 임팔라 Impala    | 하둡 기반의 실시간 SQL 질의 시스템                           |
     | 워크플로우 관리 | 우지 Oozie       | 하둡 작업을 관리하는 워크플로우 및 코디네이터 시스템         |
     | 분산 코디네이션 | 주키퍼 Zookeeper | 분산 환경에서 서버들 간에 상호 조정이 필요한 다양한 서비스를 제공<br /> 서비스를 알맞게 분산 처리, 동기화하여 데이터의 안정성을 보장 |
  
     
  
   

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

  

2. ##### 빅데이터와 인공지능 ★

   - 인간의 지적능력을 인공적으로 구현하여 컴퓨터가 인간의 지능적인 행동과 사고를 모방할 수 있도록 하는 소프트웨어



----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------



3. ##### 개인정보보호법 제도 ★

   - 개인정보보호 : 정보 주체(개인)의 개인정보 자기 결정권을 철저히 보장하는 활동

   

   - 개인정보 보호의 필요성
     	- 유출 시 피해 심각
     	- 정보사회 핵심 인프라
     	- 개인정보 자기 통제권

   

   - 빅데이터 개인정보 가이드라인 주요 내용
     	- 개인정보 비식별화
     	- 개인정보 재식별 시 조치
     	- 민감정보 처리
     	- 투명성 확보
     	- 수집정보의 보호조치

   

   - 개인정보보호 관련 법령

      - 개인정보 보호법

      - 정보통신망법

      - 신용정보법

      - 위치정보법

      - 개인정보의 안전성 확보조치 기준

        

   -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

   

   

4. ##### 개인정보 활용 ★

   - 개인정보 비식별화 : 개인정보의 일부 또는 전부를 삭제하거나 대체함으로써 다른 정보와 쉽게 결합하여도 특정 개인을 식별할 수 없도록 하는 조치

   

   - 개인정보 비식별화 절차 : 사전검토 - 비식별 조치 - 적정성 평가 - 사후관리

     

   - 개인정보 비식별 조치 방법

   - | 기법          | 세부기술                                                     | 예시                                                         |
     | ------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
     | 가명처리      | 휴리스틱 익명화<br /> 암호화<br /> 교환방법                  | 개인 식별이 가능한 데이터에 대하여 직접 식별할 수 없는다른 값으로 대체하는 기법 |
     | 총계처리      | 총계처리 기본 방식<br /> 부분집계<br /> 라운딩<br /> 데이터 재배열 | 개인정보에 대하여 통곗값을 적용하여 특정 개인을 판단할 수 없도록 하는 기법 |
     | 데이터 삭제   | 속성값 삭제<br /> 속성값 부분 삭제<br /> 식별자 제거를 통한 단순 익명화 | 개인정보 식별 가능한 특정 데이터 값 삭제 처리 기법           |
     | 데이터 범주화 | 범주화 기본 방식<br /> 랜덤 올림 방법<br /> 범위 방법<br /> 세분 정보 제한 방법<br /> 제어 올림 방법 | 해당 그룹의 대푯값으로 변환하거나 구간 값으로 변환하여 고유 정보 추적 및 식별 방지 기법 |
     | 데이터 마스킹 | 임의 잡음 추가 방법<br /> 공백과 대체 방법                   | 개인 식별 정보에 대하여 전체 또는 부분 적으로 대체값(공백, *, 노이즈 등)으로 변환하는 기법 |

     

